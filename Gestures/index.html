<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Hand Tracking with Handtrack.js</title>
  <link rel="stylesheet" href="style.css">
</head>
<body>
    <h1>Hand Gesture Detection</h1>
    <div class="container">
      <video id="myvideo" class="canvasbox" autoplay muted playsinline style="display: none;"></video>
      <canvas id="canvas" class="canvasbox"></canvas>
    </div>
    <script src="https://cdn.jsdelivr.net/npm/handtrackjs/dist/handtrack.min.js"></script>
    <script>
      const video = document.getElementById('myvideo');
      const canvas = document.getElementById('canvas');
      const context = canvas.getContext('2d');
      let model = null;
  
      const modelParams = {
        flipHorizontal: true,
        maxNumBoxes: 1, // Detect one hand at a time
        iouThreshold: 0.5,
        scoreThreshold: 0.6,
      };
  
      // Gesture-specific functions
      function onOpenHand() {
        console.log("Open hand detected");
      }
  
      function onClosedHand() {
        console.log("Closed hand detected");
      }
  
      function onPinch() {
        console.log("Pinch gesture detected");
      }
  
      function onPoint() {
        console.log("Point gesture detected");
      }
  
      // Analyze predictions for gesture detection
      function detectGestures(predictions) {
        predictions.forEach(prediction => {
          const { bbox, score } = prediction;
          const [x, y, width, height] = bbox;
  
          // Example gesture detection logic (simplified):
          if (width > 150 && height > 150) {
            // Assume an open hand if the bounding box is large
            onOpenHand();
          } else if (width < 100 && height < 100) {
            // Assume a closed hand if the bounding box is small
            onClosedHand();
          } else if (width > 100 && width < 150 && height > 50 && height < 100) {
            // Assume a pinch gesture
            onPinch();
          } else if (width < 70 && height > 150) {
            // Assume a point gesture
            onPoint();
          }
        });
      }
  
      // Start video and model detection
      function startVideo() {
        handTrack.startVideo(video).then(function (status) {
          if (status) {
            detectHand();
          } else {
            console.log('Please enable your webcam');
          }
        });
      }
  
      // Detect hands and render predictions
      function detectHand() {
        model.detect(video).then(predictions => {
          context.clearRect(0, 0, canvas.width, canvas.height);
          model.renderPredictions(predictions, canvas, context, video);
  
          detectGestures(predictions); // Analyze gestures
  
          requestAnimationFrame(detectHand);
        });
      }
  
      // Load the model and start
      handTrack.load(modelParams).then(lmodel => {
        model = lmodel;
        startVideo();
      });
    </script>
  </body>
</html>
